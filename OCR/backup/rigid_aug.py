import cv2
import numpy as np
from PIL import Image, ImageEnhance, ImageFilter, ImageOps,ImageDraw
import random
import shutil
from scipy.ndimage.interpolation import map_coordinates
from scipy.ndimage.filters import gaussian_filter
from random import randint,choice
import math
import os
import torch
import pybboxes
from interp_torch import interp
import time

device = torch.device("cuda:0" if torch.cuda.is_available() else 'cpu') 

    
def rigid(dir,value,outdir,n):
    start = time.time()
    '''
    A function that generates augmented images by applying rigid transformation to the images with random values.

    Parameters:
    dir (str): The path of the input directory.
    value (int): The random value.
    outdir (str): The path of the output directory.
    n (int): The number of times the image should be augmented.
    '''
        # ------------------------ Moving Least square ------------- rigid deformation ------------------------------------
    np.seterr(divide='ignore', invalid='ignore')

    def mls_rigid_deformation_cpu(vy, vx, p, q, alpha=1.0, eps=1e-8):
        """ Rigid deformation
        
        Parameters
        ----------
        vx, vy: ndarray
            coordinate grid, generated by np.meshgrid(gridX, gridY)
        p: ndarray
            an array with size [n, 2], original control points, in (y, x) formats
        q: ndarray
            an array with size [n, 2], final control points, in (y, x) formats
        alpha: float
            parameter used by weights
        eps: float
            epsilon
        
        Return
        ------
            A deformed image.
        """
        q = np.ascontiguousarray(q.astype(np.int16))
        p = np.ascontiguousarray(p.astype(np.int16))

        # Exchange p and q and hence we transform destination pixels to the corresponding source pixels.
        p, q = q, p

        grow = vx.shape[0]  # grid rows
        gcol = vx.shape[1]  # grid cols
        ctrls = p.shape[0]  # control points

        # Compute
        reshaped_p = p.reshape(ctrls, 2, 1, 1)                                              # [ctrls, 2, 1, 1]
        reshaped_v = np.vstack((vx.reshape(1, grow, gcol), vy.reshape(1, grow, gcol)))      # [2, grow, gcol]
        
        w = 1.0 / (np.sum((reshaped_p - reshaped_v).astype(np.float32) ** 2, axis=1) + eps) ** alpha    # [ctrls, grow, gcol]
        w /= np.sum(w, axis=0, keepdims=True)                                               # [ctrls, grow, gcol]

        pstar = np.zeros((2, grow, gcol), np.float32)
        for i in range(ctrls):
            pstar += w[i] * reshaped_p[i]                                                   # [2, grow, gcol]

        vpstar = reshaped_v - pstar                                                         # [2, grow, gcol]
        reshaped_vpstar = vpstar.reshape(2, 1, grow, gcol)                                  # [2, 1, grow, gcol]
        neg_vpstar_verti = vpstar[[1, 0],...]                                               # [2, grow, gcol]
        neg_vpstar_verti[1,...] = -neg_vpstar_verti[1,...]                                  
        reshaped_neg_vpstar_verti = neg_vpstar_verti.reshape(2, 1, grow, gcol)              # [2, 1, grow, gcol]
        mul_right = np.concatenate((reshaped_vpstar, reshaped_neg_vpstar_verti), axis=1)    # [2, 2, grow, gcol]
        reshaped_mul_right = mul_right.reshape(2, 2, grow, gcol)                            # [2, 2, grow, gcol]

        # Calculate q
        reshaped_q = q.reshape((ctrls, 2, 1, 1))                                            # [ctrls, 2, 1, 1]
        qstar = np.zeros((2, grow, gcol), np.float32)
        for i in range(ctrls):
            qstar += w[i] * reshaped_q[i]                                                   # [2, grow, gcol]
        
        temp = np.zeros((grow, gcol, 2), np.float32)
        for i in range(ctrls):
            phat = reshaped_p[i] - pstar                                                    # [2, grow, gcol]
            reshaped_phat = phat.reshape(1, 2, grow, gcol)                                  # [1, 2, grow, gcol]
            reshaped_w = w[i].reshape(1, 1, grow, gcol)                                     # [1, 1, grow, gcol]
            neg_phat_verti = phat[[1, 0]]                                                   # [2, grow, gcol]
            neg_phat_verti[1] = -neg_phat_verti[1]
            reshaped_neg_phat_verti = neg_phat_verti.reshape(1, 2, grow, gcol)              # [1, 2, grow, gcol]
            mul_left = np.concatenate((reshaped_phat, reshaped_neg_phat_verti), axis=0)     # [2, 2, grow, gcol]
            
            A = np.matmul((reshaped_w * mul_left).transpose(2, 3, 0, 1), 
                            reshaped_mul_right.transpose(2, 3, 0, 1))                       # [grow, gcol, 2, 2]

            qhat = reshaped_q[i] - qstar                                                    # [2, grow, gcol]
            reshaped_qhat = qhat.reshape(1, 2, grow, gcol).transpose(2, 3, 0, 1)            # [grow, gcol, 1, 2]

            # Get final image transfomer -- 3-D array
            temp += np.matmul(reshaped_qhat, A).reshape(grow, gcol, 2)                      # [grow, gcol, 2]

        temp = temp.transpose(2, 0, 1)                                                      # [2, grow, gcol]
        normed_temp = np.linalg.norm(temp, axis=0, keepdims=True)                           # [1, grow, gcol]
        normed_vpstar = np.linalg.norm(vpstar, axis=0, keepdims=True)                       # [1, grow, gcol]
        transformers = temp / normed_temp * normed_vpstar  + qstar                          # [2, grow, gcol]
        nan_mask = normed_temp[0] == 0

        # Replace nan values by interpolated values
        nan_mask_flat = np.flatnonzero(nan_mask)
        nan_mask_anti_flat = np.flatnonzero(~nan_mask)
        transformers[0][nan_mask] = np.interp(nan_mask_flat, nan_mask_anti_flat, transformers[0][~nan_mask])
        transformers[1][nan_mask] = np.interp(nan_mask_flat, nan_mask_anti_flat, transformers[1][~nan_mask])

        # Remove the points outside the border
        transformers[transformers < 0] = 0
        transformers[0][transformers[0] > grow - 1] = 0
        transformers[1][transformers[1] > gcol - 1] = 0
        
        return transformers.astype(np.int16)

    def mls_rigid_deformation_gpu(vy, vx, p, q, alpha=1.0, eps=1e-8):
        """ Rigid deformation
        
        Parameters
        ----------
        vx, vy: torch.Tensor
            coordinate grid, generated by torch.meshgrid(gridX, gridY)
        p: torch.Tensor
            an array with size [n, 2], original control points, in (y, x) formats
        q: torch.Tensor
            an array with size [n, 2], final control points, in (y, x) formats
        alpha: float
            parameter used by weights
        eps: float
            epsilon
        
        Return
        ------
            A deformed image.
        """
        device = q.device
        q = q.short()
        p = p.short()

        # Exchange p and q and hence we transform destination pixels to the corresponding source pixels.
        p, q = q, p

        grow = vx.shape[0]  # grid rows
        gcol = vx.shape[1]  # grid cols
        ctrls = p.shape[0]  # control points

        # Compute
        reshaped_p = p.reshape(ctrls, 2, 1, 1)                                              # [ctrls, 2, 1, 1]
        reshaped_v = torch.cat((vx.reshape(1, grow, gcol), vy.reshape(1, grow, gcol)), dim=0)      # [2, grow, gcol]
        
        w = 1.0 / (torch.sum((reshaped_p - reshaped_v).float() ** 2, dim=1) + eps) ** alpha    # [ctrls, grow, gcol]
        w /= torch.sum(w, dim=0, keepdim=True)                                               # [ctrls, grow, gcol]
        
        pstar = torch.zeros((2, grow, gcol), dtype=torch.float32).to(device)
        for i in range(ctrls):
            pstar += w[i] * reshaped_p[i]                                                   # [2, grow, gcol]

        vpstar = reshaped_v - pstar                                                         # [2, grow, gcol]
        reshaped_vpstar = vpstar.reshape(2, 1, grow, gcol)                                  # [2, 1, grow, gcol]
        neg_vpstar_verti = vpstar[[1, 0],...]                                               # [2, grow, gcol]
        neg_vpstar_verti[1,...] = -neg_vpstar_verti[1,...]                                  
        reshaped_neg_vpstar_verti = neg_vpstar_verti.reshape(2, 1, grow, gcol)              # [2, 1, grow, gcol]
        mul_right = torch.cat((reshaped_vpstar, reshaped_neg_vpstar_verti), dim=1)    # [2, 2, grow, gcol]
        reshaped_mul_right = mul_right.reshape(2, 2, grow, gcol)                            # [2, 2, grow, gcol]

        # Calculate q
        reshaped_q = q.reshape((ctrls, 2, 1, 1))                                            # [ctrls, 2, 1, 1]
        qstar = torch.zeros((2, grow, gcol), dtype=torch.float32).to(device)
        for i in range(ctrls):
            qstar += w[i] * reshaped_q[i]                                                   # [2, grow, gcol]
        
        temp = torch.zeros((grow, gcol, 2), dtype=torch.float32).to(device)
        for i in range(ctrls):
            phat = reshaped_p[i] - pstar                                                    # [2, grow, gcol]
            reshaped_phat = phat.reshape(1, 2, grow, gcol)                                  # [1, 2, grow, gcol]
            reshaped_w = w[i].reshape(1, 1, grow, gcol)                                     # [1, 1, grow, gcol]
            neg_phat_verti = phat[[1, 0]]                                                   # [2, grow, gcol]
            neg_phat_verti[1] = -neg_phat_verti[1]
            reshaped_neg_phat_verti = neg_phat_verti.reshape(1, 2, grow, gcol)              # [1, 2, grow, gcol]
            mul_left = torch.cat((reshaped_phat, reshaped_neg_phat_verti), dim=0)     # [2, 2, grow, gcol]
            
            A = torch.matmul((reshaped_w * mul_left).permute(2, 3, 0, 1), 
                            reshaped_mul_right.permute(2, 3, 0, 1))                       # [grow, gcol, 2, 2]

            qhat = reshaped_q[i] - qstar                                                    # [2, grow, gcol]
            reshaped_qhat = qhat.reshape(1, 2, grow, gcol).permute(2, 3, 0, 1)            # [grow, gcol, 1, 2]

            # Get final image transfomer -- 3-D array
            temp += torch.matmul(reshaped_qhat, A).reshape(grow, gcol, 2)                      # [grow, gcol, 2]

        temp = temp.permute(2, 0, 1)                                                      # [2, grow, gcol]
        normed_temp = torch.norm(temp, dim=0, keepdim=True)                           # [1, grow, gcol]
        normed_vpstar = torch.norm(vpstar, dim=0, keepdim=True)                       # [1, grow, gcol]
        transformers = temp / normed_temp * normed_vpstar  + qstar                          # [2, grow, gcol]
        nan_mask = normed_temp[0] == 0

        # Replace nan values by interpolated values
        nan_mask_flat = torch.nonzero(nan_mask.view(-1), as_tuple=True)[0]
        nan_mask_anti_flat = torch.nonzero(~nan_mask.view(-1), as_tuple=True)[0]
        transformers[0][nan_mask] = interp(nan_mask_flat, nan_mask_anti_flat, transformers[0][~nan_mask])
        transformers[1][nan_mask] = interp(nan_mask_flat, nan_mask_anti_flat, transformers[1][~nan_mask])

        # Remove the points outside the border
        transformers[transformers < 0] = 0
        transformers[0][transformers[0] > grow - 1] = 0
        transformers[1][transformers[1] > gcol - 1] = 0
        
        return transformers.long()
        
        # ------------------ Return the rigid Deformation Image ---------------------------
    def demo_auto_cpu(p,q,image):  
        
        height, width,_= image.shape
        gridX = np.arange(width, dtype=np.int16)
        gridY = np.arange(height, dtype=np.int16)
        vy, vx = np.meshgrid(gridX, gridY)

        rigid = mls_rigid_deformation_cpu(vy, vx, p, q, alpha=1)
        aug3 = np.ones_like(image)
        aug3[vx, vy] = image[tuple(rigid)]
        return aug3
    
    def demo_auto_gpu(p,q,image):
        p = torch.tensor(p).to(device)
        q = torch.tensor(q).to(device)

        image_ = image.copy()
        image = torch.tensor(image_).to(device)
        
        height, width, _ = image.shape
        gridX = torch.arange(width, dtype=torch.int16).to(device)
        gridY = torch.arange(height, dtype=torch.int16).to(device)
        vy, vx = torch.meshgrid(gridX, gridY)
        # !!! Pay attention !!!: the shape of returned tensors are different between numpy.meshgrid and torch.meshgrid
        vy, vx = vy.transpose(0, 1), vx.transpose(0, 1)
        
        start1 = time.time()
        rigid = mls_rigid_deformation_gpu(vy, vx, p, q, alpha=1)
        # print("Time taken by mls rigid",time.time()-start1)
        aug3 = torch.ones_like(image).to(device)
        aug3[vx.long(), vy.long()] = image[tuple(rigid)]

        return aug3
        
    # ------------------------ Function to get random coordinates with respect with given shift value -------------
    def RandMove(old_pnt,min_shift,max_shift):
        neg = [-1,1]

        #get the first point from the geometry object
        old_x = old_pnt[0]
        old_y = old_pnt[1]

        #calculate new coordinates
        new_x = old_x + (choice(neg) * randint(min_shift,max_shift))
        new_y = old_y + (choice(neg) * randint(min_shift,max_shift))
        
        return (new_x,new_y)
    
    # ------------------------------ Function to get random p and q control points -------------------------
    def check_p_q(coordinates,distance,control_points):
        if coordinates == []:

            return [],[]
        else:
            p_coordinates = []
            q_coordinates = []
            while True:
                if (len(q_coordinates) == control_points):
                    break
                else:
                    x, y = random.choice(coordinates)
                    old_co = (x,y)
                    new_co = RandMove(old_co,-distance,distance)
                    # Check if the new coordinates are within the given list of coordinates
                    if new_co in coordinates:
                        
                        p_coordinates.append(old_co)
                        q_coordinates.append(new_co)
                    else:
                        pass
                        # print("no")
            return p_coordinates,q_coordinates
    
    #----------------------------------Function to find all the coordinates lie inside the boundary box ----------------
    def find_all_coordinates(x1,y1,x2,y2,x3,y3,x4,y4):
        # Create an empty list to hold the coordinates
        coordinates = []
        # Loop over the x values between the left and right edges of the rectangle
        for x in range(min(x1, x2, x3, x4), max(x1, x2, x3, x4) + 1):
            # Loop over the y values between the top and bottom edges of the rectangle
            for y in range(min(y1, y2, y3, y4), max(y1, y2, y3, y4) + 1):
                # Check if the current coordinate is inside the rectangle
                if (x2-x1)*(y-y1) - (y2-y1)*(x-x1) >= 0 and (x3-x2)*(y-y2) - (y3-y2)*(x-x2) >= 0 and (x4-x3)*(y-y3) - (y4-y3)*(x-x3) >= 0 and (x1-x4)*(y-y4) - (y1-y4)*(x-x4) >= 0:
                    # Append the current coordinate to the list
                    coordinates.append((x, y))               
        return coordinates
    
    def return_all_x_and_y(my_list):
        x1,y1 = int(my_list[0]),int(my_list[1])
        x2,y2 = int(my_list[2]),int(my_list[3])
        x3,y3 = int(my_list[4]),int(my_list[5])
        x4,y4 = int(my_list[6]),int(my_list[7])
        return x1,y1,x2,y2,x3,y3,x4,y4
    
    def tensor_to_cpu_image(tensor):
        # Move tensor to CPU and convert to NumPy array
        image_np_1 = tensor.cpu().numpy()
        # print("shape",image_np.shape)
        # show_image("deform",image_np)

        # Convert from CHW to HWC (assuming tensor is in CHW format)
        image_np = np.transpose(image_np_1, (1, 2, 0))
        # Convert to uint8 (assuming image is in float format)
        image_np_after_transpose = (image_np * 255).astype(np.uint8)
        return image_np_1,image_np_after_transpose
    

    def return_from_to(path,x1,y1,x2,y2,x3,y3,x4,y4):
        im = Image.open(path)

        # Define the two points between which to find coordinates

        li = []
        # Create a new image with the same size as the original image
        new_im = Image.new('RGB', im.size, (255, 255, 255))

        # Draw a line between the two points on the new image
        draw1 = ImageDraw.Draw(new_im)
        draw1.line((x1, y1, x2, y2), fill='black')

        draw2 = ImageDraw.Draw(new_im)
        draw2.line((x2, y2, x3, y3), fill='black')

        draw3 = ImageDraw.Draw(new_im)
        draw3.line((x4, y4, x3, y3), fill='black')

        draw4 = ImageDraw.Draw(new_im)
        draw4.line((x1, y1, x4, y4), fill='black')

        # Iterate over all the pixels in the new image and print the coordinates of the black pixels
        for x in range(new_im.size[0]):
            for y in range(new_im.size[1]):
                if new_im.getpixel((x, y)) == (0, 0, 0):
                    li.append((x,y))

        select_control_points_no = int(len(li)/20)
        select_control_points = random.sample(li, select_control_points_no)
        return select_control_points

    # Open the file for reading
    path = dir
    img = dir
    
    img4=dir
    img3=Image.open(img4)
    img2 = cv2.cvtColor(np.array(img3), cv2.COLOR_RGB2BGR)
    img2_copy = img2.copy()
    new_blank_image = np.zeros_like(img2,dtype='uint8')
    bb=img4.replace('.jpg','.txt')
    
    my_list = []

    with open(bb, 'r') as file:
        lent = len(file.readlines())

    file.close()

    if type=='paddle':    
        for i in range(lent):
        # Open the file for reading
            with open(bb, 'r') as file:
                line = file.readlines()[i].split(',')[:-1]
                my_list.append(line)
    
    elif type=="yolo":
        f=open(bb,'r')
        x=(float(f.readlines()[0].split(" ")[1:][0]))
        f.close()

        f=open(bb,'r')
        y=(float(f.readlines()[0].split(" ")[1:][1]))
        f.close()

        f=open(bb,'r')
        w=(float(f.readlines()[0].split(" ")[1:][2]))
        f.close()

        f=open(bb,'r')
        h=(float(f.readlines()[0].split(" ")[1:][3]))
        f.close()

        image_w=img2.size[0]
        image_h=img2.size[1]

        w = w * image_w
        h = h * image_h
        x1 = ((2 * x * image_w) - w)/2
        y1 = ((2 * y * image_h) - h)/2
        x2 = x1 + w
        y2 = y1 + h

        xmin = round(x1)
        xmax = round(x2)
        ymin = round(y1)
        ymax = round(y2)
        
        my_list=[xmin, ymax, xmax, ymax, xmax, ymin, xmin, ymin]

    else:
        for i in range(lent):
        # Open the file for reading
            with open(bb, 'r') as file:
                line = file.readlines()[i].split(',')[:-1]
                my_list.append(line)
    # distance= 10
    points = value
    # an = time.time()
    for i in range(len(my_list)):
        x1,y1,x2,y2,x3,y3,x4,y4 = return_all_x_and_y(my_list[i])
        all_coordinates = find_all_coordinates(x1,y1,x2,y2,x3,y3,x4,y4)
        select_control_points = return_from_to(path,x1,y1,x2,y2,x3,y3,x4,y4)
        P_Points,Q_Points = check_p_q(all_coordinates,value,points)
        # print("Analy
        # sis",time.time() - an)
        #--------- new random points p and q
        points_in_p =  P_Points  + select_control_points
        points_in_q =  Q_Points + select_control_points
        #----- into array
        points_in_p = np.array(points_in_p)
        points_in_q = np.array(points_in_q)

        #------ points x,y into y,x-----
        for i in range(len(points_in_p)):
            # for p swap
            temp = points_in_p[i][0]
            points_in_p[i][0] = points_in_p[i][1]
            points_in_p[i][1] = temp

            #for q swap
            temp1 = points_in_q[i][0]
            points_in_q[i][0] = points_in_q[i][1]
            points_in_q[i][1] = temp1
        
        # ------------ Function called -------------
        # if device == 'cuda:0':
        ans = time.time()
        img_deformation = demo_auto_gpu(points_in_p,points_in_q,img2_copy)
        img_deformation,image_np_after_transpose = tensor_to_cpu_image(img_deformation)
        # print("Demo Function time",time.time()-ans)
        # print("shape original:",img2.shape)
        # print("rigid shape",img_deformation.shape)
        # show_image("after complete but",img_deformation)
    
        
        # else:
        #     img_deformation = demo_auto_cpu(points_in_p,points_in_q,img2)


        # img_deformation = cv2.cvtColor(img_deformation,cv2.COLOR_RGB2BGR)
        img2_copy = img_deformation.copy()

    # show_image("after complete",img2_copy)
    # img5 = Image.fromarray(cv2.cvtColor(img2_copy, cv2.COLOR_BGR2RGB))
    img5 = Image.fromarray(img2_copy)
    img_name = os.path.basename(img)
    img5.save(outdir+img_name)
    text_path = os.path.basename(bb)
    # shutil.move(bb,outdir+text_path)
    Image.open(outdir+img_name)
    # print("Rigid TIme:",time.time()-st)
    return img, bb

#rigid("C:\\Users\\User\\Desktop\\Augmentation_Software\\Data_Augmentation\\OCR\\samples",10,'C:\\Users\\User\\Desktop\\Augmentation_Software\\Data_Augmentation\\OCR\\samples\\output',3)


dir = r'C:\Users\User\Desktop\Augmentation_Software\Data_Augmentation\OCR\samples'
dir_o = 'C:/Users/User/Desktop/Augmentation_Software/Data_Augmentation/OCR/output/'
file = os.listdir(dir)

for i in file:
    starts = time.time()
    for j in range(100):
        if i.endswith('.jpg'):
            filename = os.path.join(dir,i)
            # print(filename)
            rigid(filename,15,dir_o,3)
print("Time taken in",time.time() - starts)